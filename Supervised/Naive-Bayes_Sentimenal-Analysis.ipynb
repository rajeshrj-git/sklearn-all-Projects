{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad558c58-625a-4d1b-83ff-9ab897905752",
   "metadata": {},
   "source": [
    "# Sentimental Analyzing Based on Product Review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d3de0f71-384e-4ebc-8420-06eabb8adc07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84a51d1d-3fab-4158-a7d8-b022d92e4f0d",
   "metadata": {},
   "source": [
    "# Importing the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5f345df6-6c83-4da6-8401-cdc888105375",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Liked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wow... Loved this place.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Crust is not good.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Not tasty and the texture was just nasty.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stopped by during the late May bank holiday of...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The selection on the menu was great and so wer...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Review  Liked\n",
       "0                           Wow... Loved this place.      1\n",
       "1                                 Crust is not good.      0\n",
       "2          Not tasty and the texture was just nasty.      0\n",
       "3  Stopped by during the late May bank holiday of...      1\n",
       "4  The selection on the menu was great and so wer...      1"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(r\"C:\\Users\\rajes\\Downloads\\Produc_review.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "63d92825-0ff5-404a-9122-c6d0f776ce53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 900 entries, 0 to 899\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   Review  900 non-null    object\n",
      " 1   Liked   900 non-null    int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 14.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b2d0fc9-0ce7-41d7-973d-7b343e4b58ec",
   "metadata": {},
   "source": [
    "# Removing Expression and stop Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "52afcaa7-4bda-44aa-ba44-9bbe8258a53f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Liked</th>\n",
       "      <th>Clean review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wow... Loved this place.</td>\n",
       "      <td>1</td>\n",
       "      <td>wow loved place</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Crust is not good.</td>\n",
       "      <td>0</td>\n",
       "      <td>crust good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Not tasty and the texture was just nasty.</td>\n",
       "      <td>0</td>\n",
       "      <td>tasty texture was just nasty</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      Review  Liked  \\\n",
       "0                   Wow... Loved this place.      1   \n",
       "1                         Crust is not good.      0   \n",
       "2  Not tasty and the texture was just nasty.      0   \n",
       "\n",
       "                   Clean review  \n",
       "0               wow loved place  \n",
       "1                    crust good  \n",
       "2  tasty texture was just nasty  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re \n",
    "length = len(df['Review'])\n",
    "\n",
    "stopwords =set(['the', 'is', 'in', 'and', 'to', 'a', 'of', 'for', 'it', 'not', 'this', 'that', 'with', 'as', 'on', 'at', 'by', 'an', 'be'])\n",
    "\n",
    "clean_review = []\n",
    "for i in range(length):\n",
    "    review = re.sub('[^a-zA-Z]',' ',df['Review'][i])\n",
    "    review = review.lower()\n",
    "    review = review.split()\n",
    "    review = [ word for word in review if word not in stopwords]\n",
    "    review = ' '.join(review)\n",
    "    clean_review.append(review)\n",
    "    \n",
    "df['Clean review'] = clean_review\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69303c88-14ea-4bb9-931d-d14b51f2f049",
   "metadata": {},
   "source": [
    "# Using naive bayes for probability Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "aa8e8890-9cad-4785-b707-8a4a33765121",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 6 folds for each of 10 candidates, totalling 60 fits\n",
      "Best Naive Bayes Model Parameters: {'fit_prior': True, 'alpha': 0.3593813663804626}\n",
      "Fitting 6 folds for each of 10 candidates, totalling 60 fits\n",
      "Best Gradient Boosting Model Parameters: {'n_estimators': 300, 'max_depth': 7, 'learning_rate': 0.1}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.ensemble import GradientBoostingClassifier, StackingClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV, KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "X = df['Clean review']\n",
    "y = df['Liked']\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "X_vec = vectorizer.fit_transform(X).toarray()\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_vec, y, test_size=0.2, random_state=42)\n",
    "\n",
    "param_distributions = {\n",
    "    'alpha': np.logspace(-4, 4, 10),\n",
    "    'fit_prior': [True, False]\n",
    "}\n",
    "\n",
    "kf = KFold(n_splits=6, shuffle=True, random_state=42)\n",
    "\n",
    "mnb = MultinomialNB()\n",
    "random_search = RandomizedSearchCV(mnb, param_distributions=param_distributions, cv=kf, scoring='accuracy', verbose=1, random_state=42)\n",
    "random_search.fit(X_train, y_train)\n",
    "best_nb_model = random_search.best_estimator_\n",
    "\n",
    "print(\"Best Naive Bayes Model Parameters:\", random_search.best_params_)\n",
    "\n",
    "\n",
    "gbr = GradientBoostingClassifier()\n",
    "gbr_param_distributions = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'max_depth': [3, 5, 7]\n",
    "}\n",
    "gbr_random_search = RandomizedSearchCV(gbr, param_distributions=gbr_param_distributions, cv=kf, scoring='accuracy', verbose=1, random_state=42)\n",
    "gbr_random_search.fit(X_train, y_train)\n",
    "best_gbr_model = gbr_random_search.best_estimator_\n",
    "\n",
    "print(\"Best Gradient Boosting Model Parameters:\", gbr_random_search.best_params_)\n",
    "\n",
    "\n",
    "stacking_clf = StackingClassifier(\n",
    "    estimators=[('mnb', best_nb_model), ('gbr', best_gbr_model)],\n",
    "    final_estimator=GradientBoostingClassifier() \n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "stacking_clf.fit(X_train, y_train)\n",
    "y_pred = stacking_clf.predict(X_test)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed6a870f",
   "metadata": {},
   "source": [
    "# Cross Valiadtion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "95fd7b53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stacking Classifier CV Scores: [0.7        0.79166667 0.71666667 0.75       0.73333333 0.725     ]\n",
      "Mean : 0.74\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "stacking_clf_cv_scores = cross_val_score(stacking_clf, X_train, y_train, cv=kf, scoring='accuracy')\n",
    "\n",
    "print(f\"Stacking Classifier CV Scores: {stacking_clf_cv_scores}\")\n",
    "print(f\"Mean : {np.mean(stacking_clf_cv_scores):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81c7ae18-e763-4a12-859f-63b91e991c83",
   "metadata": {},
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "56331a17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.77\n",
      "Precision: 0.80\n",
      "Recall: 0.76\n",
      "F1-score: 0.78\n",
      "Accuracy Percentage: 76.67\n",
      "\n",
      "Confusion Matrix:\n",
      "[[64 18]\n",
      " [24 74]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.78      0.75        82\n",
      "           1       0.80      0.76      0.78        98\n",
      "\n",
      "    accuracy                           0.77       180\n",
      "   macro avg       0.77      0.77      0.77       180\n",
      "weighted avg       0.77      0.77      0.77       180\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix, classification_report\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"Recall: {recall:.2f}\")\n",
    "print(f\"F1-score: {f1:.2f}\")\n",
    "acc_per = accuracy * 100\n",
    "print(f\"Accuracy Percentage: {acc_per:.2f}\")\n",
    "\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "print(\"\\nClassification Report:\")\n",
    "print(class_report)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10d1639f",
   "metadata": {},
   "source": [
    "# Adding new Reviews for new Sentimental Analyzing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e193f474-20fa-496a-9b55-d866ff46a9e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I absolutely love this product - Sentiment: Positive\n",
      "This was a terrible purchase - Sentiment: Negative\n"
     ]
    }
   ],
   "source": [
    "def predict_sentiment(review):\n",
    "    review_cleaned = re.sub('[^a-zA-Z]', ' ', review).lower().split()\n",
    "    review_cleaned = ' '.join([word for word in review_cleaned if word not in stopwords])\n",
    "    review_vec = vectorizer.transform([review_cleaned]).toarray()\n",
    "    prediction = stacking_clf.predict(review_vec)\n",
    "    return 'Positive' if prediction[0] == 1 else 'Negative'\n",
    "\n",
    "new_review = \"I absolutely love this product\"\n",
    "print(f\"{new_review} - Sentiment: {predict_sentiment(new_review)}\")\n",
    "\n",
    "new_review = \"This was a terrible purchase\"\n",
    "print(f\"{new_review} - Sentiment: {predict_sentiment(new_review)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd317f78-1229-4773-8d5c-4ada5748762e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9d300ce-fdf6-4bef-b8e1-c3ffe8065f16",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30af0ae5-55f9-4cdc-b2b7-8023ca76c6d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78cb65b1-f3c1-4ef6-a6f2-ece42fc5df24",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36564fd2-35b7-4898-97be-b2c0a11f834e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9be4410a-5b6c-49cc-9100-9a671a3bce82",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd3e0404-757a-491e-893a-29aa6b985ccf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d4420e6-e886-4f3b-985d-731237911db3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
